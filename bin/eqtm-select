#! /usr/bin/env python
import argparse
import logging
from concurrent.futures import ProcessPoolExecutor
from importlib import resources
from itertools import repeat
from pathlib import Path
from time import perf_counter as timer

import pandas as pd
from fastavro.schema import load_schema

import correlation_detector as cd

parser = argparse.ArgumentParser(prog=__file__)
parser.add_argument("list", help="Path to event catalog, location of the zmap file", type=Path)
parser.add_argument("input", help="Input file path, location of the avro file", type=Path)
parser.add_argument("output", help="Output file path, stem of the output cat and stats file", type=Path)
parser.add_argument("--time_unit", help="Tolerance in seconds", type=str, default='1ms')
parser.add_argument("--log", help="Log level", default='info')

cli_args = parser.parse_args()

logging.basicConfig(format='%(levelname)s-%(asctime)s: %(message)s',
                    level=getattr(logging, cli_args.log.upper()))

with resources.path('correlation_detector', 'event.avsc') as schema_path:
    schema = load_schema(schema_path)


if __name__ == '__main__':
    logging.info(f"Running {parser.prog} with the following parameters: {vars(cli_args)}")
    tic = timer()
    selection = pd.read_csv(cli_args.list, usecols=[0, 1], names=['template', 'date'], delimiter=' ')
    selection['date'] = pd.to_datetime(selection['date'], utc=True)
    dt = pd.to_timedelta(cli_args.time_unit)
    filenames = cd.filenames_from_dates(selection['date'], root=cli_args.input)
    with ProcessPoolExecutor() as pool:
        catalogue = pd.concat(filter(lambda df: isinstance(df, pd.DataFrame) and not df.empty,
                                     pool.map(cd.find_records,
                                              map(lambda fn: pd.read_parquet(fn, engine='fastparquet'), filenames),
                                              repeat(selection), repeat(dt))))
    output = cli_args.output.with_suffix('.parquet')
    if output.exists():
        logging.info(f"{output} already exists, it will be overwritten")
    catalogue.to_parquet(output, engine='fastparquet', index=True)
    toc = timer()
    logging.info(f"Elapsed time: {toc - tic:.2f} seconds")
